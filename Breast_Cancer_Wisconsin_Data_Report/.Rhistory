WDBD_data=read.csv("wdbc.data",head=FALSE,sep = ",")
WDBC_data=read.csv("wdbc.data",head=FALSE,sep = ",")
WPBC_data=read.csv("wpbc.data",head=FALSE,sep = ",")
bcw_data=read.csv("breast-cancer-wisconsin.data",head=FALSE,sep = ",")
rm(WDBD_data)
library(caret)
bcw_data[-1]
bcw_data[11]
cor(bcw_data)
cor(bcw_data[-1])
bcw_data[-1]
hist(bcw_data[1])
hist(bcw_data[2])
hist(bcw_data[3])
hist(bcw_data[[3])
hist(bcw_data[[3]])
hist(bcw_data[[1]])
hist(bcw_data[[2]])
hist(bcw_data[[3]])
hist(bcw_data[[4]])
hist(bcw_data[[5]])
hist(bcw_data[[6]])
hist(bcw_data[[7]])
hist(bcw_data[[8]])
hist(bcw_data[[9]])
hist(bcw_data[[10]])
hist(bcw_data[[11]])
bcw_data[[7]]
?complete.cases
sum(!complete.cases(bcw_data))
inTrain<-createDataPartition(y=bcw_data[11],p=0.75,list=FALSE)
training<-bcw_data[inTrain]
testing<-bcw_data[-inTrain]
bcw_data[11]
bcw_data=read.csv("breast-cancer-wisconsin.data",head=FALSE,sep = ",")
inTrain<-createDataPartition(y=bcw_data[11],p=0.75,list=FALSE)
inTrain<-createDataPartition(y=bcw_data[1],p=0.75,list=FALSE)
inTrain<-createDataPartition(y=bcw_data[[1]],p=0.75,list=FALSE)
training<-bcw_data[inTrain]
testing<-bcw_data[-inTrain]
training
inTrain<-createDataPartition(y=bcw_data[[11]],p=0.75,list=FALSE)
training<-bcw_data[inTrain]
testing<-bcw_data[-inTrain]
training
dim(training)
inTrain<-createDataPartition(y=bcw_data$V11,p=0.75,list=FALSE)
training<-bcw_data[inTrain]
testing<-bcw_data[-inTrain]
dim(training)
testing<-bcw_data[-inTrain,]
inTrain<-createDataPartition(y=bcw_data$V11,p=0.75,list=FALSE)
training<-bcw_data[inTrain,]
testing<-bcw_data[-inTrain,]
dim(training)
summary(training)
hist(bcw_data$V11)
hist(bcw_data$V11,title="Class Distribution" )
hist(bcw_data$V11,head="Class Distribution" )
?hist
hist(bcw_data$V11,main = "Class Distribution" )
hist(bcw_data$V11,main = "Class Distribution" , xlab = "Target Variable" )
?train
names(getModelInfo())
train(x=bcw_data[,2:10],y=bcw_data[,11],method = "glm")
train(x=bcw_data[,2:10],y=as.factor(bcw_data[,11]),method = "glm")
train(x=training[,2:10],y=as.factor(training[,11]),method = "glm")
warnings()
train(x=training[,2:10],y=as.factor(training[,11]),method = "knn")
modelFit_1=train(x=training[,2:10],y=as.factor(training[,11]),method = "glm")
warnings()
train(x=training[,2:10],y=as.factor(training[,11]),method = "glm",na.action=na.omit)
warnings()
train(x=training[,2:10],y=as.factor(training[,11]),method = "glm",na.omit)
train(x=training[,2:10],y=as.factor(training[,11]),method = "glm",na.action(na.omit))
warnings()
?is.na
Setting NA_real_
bcw_data[-(bcw_data$V7=="?")]
dim(bcw_data[-(bcw_data$V7=="?")])
as.factor(bcw_data$V7)
dim(bcw_data[-(bcw_data$V7=="?"),])
bcw_data<-bcw_data[-(bcw_data$V7=="?"),]
inTrain<-createDataPartition(y=bcw_data$V11,p=0.75,list=FALSE)
training<-bcw_data[inTrain,]
testing<-bcw_data[-inTrain,]
dim(training)
# Summary shows that data is skewedbut when we explore the target variable we see
# that the class is well balanced.
summary(training)
# Taking a look at class distribution of target variable
hist(bcw_data$V11,main = "Class Distribution" , xlab = "Target Variable" )
# Here
# 2 -> Benign Tumor
# 4 -> Malignant Tumor
train(x=training[,2:10],y=as.factor(training[,11]),method = "glm",na.action(na.omit))
warnings()
train(x=training[,2:10],y=as.factor(training[,11]),method = "glm")
warnings()
warnings()
train(x=training[,2:10],y=as.factor(training[,11]),method = "glm")
knn.pred=knn(training[,2:10],training[,11],testing[2:10],k=2)
set.seed(1)
library(class)
knn.pred=knn(training[,2:10],training[,11],testing[2:10],k=2)
knn.pred=knn(training[,2:10],testing[2:10],training[,11],k=2)
knn.pred=knn(training[,2:10],testing[,2:10],training[,11],k=2)
knn.pred=knn(training[,2:10],testing[,2:10],training[,11],k=1)
set.seed(1)
library(class)
knn.pred=knn(training[,2:10],testing[,2:10],training[,11],k=1)
knn.pred
set.seed(1)
library(class)
knn.pred=knn(as.matrix(training[,2:10]),as.matrix(testing[,2:10]),as.matrix(training[,11]),k=1)
as.matrix(training[,2:10])
bcw_data<-bcw_data[-(bcw_data$V7=="?"),]
dim(bcw_data)
?rep
bcw_data=read.csv("breast-cancer-wisconsin.data",head=FALSE,sep = ",")
bcw_data<-bcw_data[-(bcw_data$V7==rep("?",699),]
bcw_data<-bcw_data[-(bcw_data$V7==rep("?",699)),]
dim(bcw_data)
bcw_data<-bcw_data[-(bcw_data$V7==rep("?",699)),]
rep("?",699)
bcw_data<-bcw_data[-(bcw_data$V7==rep("?",698)),]
bcw_data<-bcw_data[-(bcw_data$V7==rep("?",696)),]
bcw_data<-bcw_data[-(bcw_data$V7==rep("?",695)),]
bcw_data<-bcw_data[-(bcw_data$V7==rep("?",694)),]
bcw_data<-bcw_data[-(which(bcw_data$V7==rep("?",694))),]
bcw_data<-bcw_data[-(which(bcw_data$V7=="?")),]
bcw_data=read.csv("breast-cancer-wisconsin.data",head=FALSE,sep = ",")
which(bcw_data$V7=="?")
bcw_data<-bcw_data[-(which(bcw_data$V7=="?")),]
bcw_data<-bcw_data[-(which(bcw_data$V7=="?")),]
bcw_data=read.csv("breast-cancer-wisconsin.data",head=FALSE,sep = ",")
bcw_data<-bcw_data[-(which(bcw_data$V7=="?")),]
dim(bcw_data)
inTrain<-createDataPartition(y=bcw_data$V11,p=0.75,list=FALSE)
training<-bcw_data[inTrain,]
testing<-bcw_data[-inTrain,]
dim(training)
# Summary shows that data is skewedbut when we explore the target variable we see
# that the class is well balanced.
summary(training)
# Taking a look at class distribution of target variable
hist(bcw_data$V11,main = "Class Distribution" , xlab = "Target Variable" )
# Here
# 2 -> Benign Tumor
# 4 -> Malignant Tumor
modelFit1=train(x=training[,2:10],y=as.factor(training[,11]),method = "glm")
set.seed(1)
library(class)
knn.pred=knn(training[,2:10],testing[,2:10],training[,11],k=1)knn
knn.pred=knn(training[,2:10],testing[,2:10],training[,11],k=1)
table(knn.pred,testing$V11)
# 97.1% Accurary
summary(modelFit1)
train(x=training[,2:10],y=as.factor(training[,11]),method = "glm")
knn.pred=knn(training[,2:10],testing[,2:10],training[,11],k=3)
table(knn.pred,testing$V11)
kmeans
?kmeans
kmeans(bcw_data[,2:10],2)
kmeans(bcw_data[,2:10],2,iter.max = 100)
cluster_fit=kmeans(bcw_data[,2:10],2,iter.max = 100)
cluster_fit$cluster
hist(cluster_fit$cluster)
res=cluster_fit$cluster
?ifelse
ifelse(cluster_fit$cluster==1,2,4)
table(ifelse(cluster_fit$cluster==1,2,4),testing[,11]
)
table(ifelse(cluster_fit$cluster==1,2,4),bcw_data[,11])
#Error Metric
# accurarcy = 96.04
?kmeans
summary(WPBC_data)
cor(WPBC_data[2:35])
cor(WPBC_data[3:35])
cor(WPBC_data[3:34])
# There are features of high collinearity using PCA to
corrgrams(WPBC_data[3:34])
library(corrgram)
install.packages(corrgrams)
install.packages(corrgram)
install.packages("corrgram")
cor(WPBC_data[3:34])
# Regression
summary(WPBC_data)
inTrain1<-createDataPartition(y=WPBC_data$V3,p=0.75,list=FALSE)
training<-WPBC_data[inTrain,]
testing<-WPBC_data[-inTrain,]
dat <- training[,3:35]
knnFit2 <- train(V3~., dat, method = "lm", preProcess=c("pca"),
trControl = trainControl(method = "cv"))
knnFit2 <- train(V3~., dat, method = "lm",
trControl = trainControl(method = "cv"))
dat <- training[,3:34]
knnFit2 <- train(V3~., dat, method = "lm",
trControl = trainControl(method = "cv"))
kn.pred=predict(knnFit2,testing[4:34])
dat <- training[,3:34]
knnFit2 <- train(V3~., dat, method = "lm", preProcess=c("pca"),
trControl = trainControl(method = "cv"))
kn.pred=predict(knnFit2,testing[4:34])
sum((kn.pred-testing[,3])^2)
sum((kn.pred-testing[,3])^2)/94
knnFit2 <- train(V3~., dat, method = "lm",
trControl = trainControl(method = "cv"))
kn.pred=predict(knnFit2,testing[4:34])
sum((kn.pred-testing[,3])^2)/94
dat <- training[,2:34]
knnFit2 <- train(V3~., dat, method = "lm",
trControl = trainControl(method = "cv"))
dat <- testing[,3:34]
kn.pred=predict(knnFit2,testing[3:34])
kn.pred=predict(knnFit2,testing[2:34])
sum((kn.pred-testing[,3])^2)/94
sqrt(sum((kn.pred-testing[,3])^2)/94)
this goes off by 22 hours
# this goes off by 22 hours
summary(WPBC_data)
inTrain1<-createDataPartition(y=WPBC_data$V3,p=0.75,list=FALSE)
training<-WPBC_data[inTrain,]
testing<-WPBC_data[-inTrain,]
dat <- training[,2:34]
lmFit1 <- train(V3~., dat, method = "lm", preProcess=c("pca"),
trControl = trainControl(method = "cv"))
lmFit1.pred<-predict(lmFit1,testing[2:34])
sqrt(sum((kn.pred-testing[,3])^2)/94)
# This goes off by
lmFit2 <- train(V3~., dat, method = "lm",
trControl = trainControl(method = "cv"))
lmFit2.pred<-predict(lmFit2,testing[2:34])
sqrt(sum((kn.pred-testing[,3])^2)/94)
# this goes off by 22 hours
# As the data has many correlated features PCA is used to reduce the number of
# features for better and improved prediction but the results does not support
# the arguement
# Cross validation was used to better generalise the error
lmFit1 <- train(V3~., dat, method = "lm", preProcess=c("pca"),
trControl = trainControl(method = "cv"))
lmFit1.pred<-predict(lmFit1,testing[2:34])
sqrt(sum((lmFit1.pred-testing[,3])^2)/94)
# This goes off by
lmFit2 <- train(V3~., dat, method = "lm",
trControl = trainControl(method = "cv"))
lmFit2.pred<-predict(lmFit2,testing[2:34])
sqrt(sum((lmFit2.pred-testing[,3])^2)/94)
# this goes off by 22 hours
# As the data has many correlated features PCA is used to reduce the number of
# features for better and improved prediction but the results does not support
# the arguement
# Cross validation was used to better generalise the error
```{r echo=FALSE}
rm(list=ls())
cluster_fit=kmeans(bcw_data[,2:10],2,iter.max = 100)
hist(cluster_fit$cluster)
res=cluster_fit$cluster
p=table(ifelse(res==1,2,4),bcw_data[,11])
print(p)
accuracy=p[1,1]+p[2,2]/length(cluster_fit$cluster)
accuracy
